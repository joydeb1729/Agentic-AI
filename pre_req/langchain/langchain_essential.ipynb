{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "672358d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a76b9e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c690541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eacbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "LANGSMITH_TRACING=os.getenv(\"LANGSMITH_TRACING_V2\", \"true\")  # Default to \"true\" if not set\n",
    "LANGSMITH_ENDPOINT=os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "LANGSMITH_API_KEY=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT=os.getenv(\"LANGSMITH_PROJECT\")\n",
    "\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGSMITH_TRACING_V2\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e2d86",
   "metadata": {},
   "source": [
    "### Load the model and test it with a simple message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1e602cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8b45de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    convert_system_message_to_human=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "01650614",
   "metadata": {},
   "outputs": [],
   "source": [
    "message1 = [SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "           HumanMessage(content=\"I need your help\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f7cd96b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, I'm ready to help! Tell me what you need. The more information you give me, the better I can assist you. For example, you could tell me:\\n\\n*   **What you're trying to achieve:** What is your goal?\\n*   **What you've already tried:** What steps have you taken so far?\\n*   **What problems you're encountering:** What's blocking you?\\n*   **What kind of help you need:** Are you looking for information, code, creative writing, brainstorming, or something else?\\n\\nI can help with a wide range of tasks, including:\\n\\n*   Answering questions\\n*   Generating text (stories, poems, code, etc.)\\n*   Summarizing information\\n*   Translating languages\\n*   Brainstorming ideas\\n*   Providing definitions\\n*   Offering advice (though I'm not a substitute for professional advice)\\n\\nI'm looking forward to hearing from you! Let me know how I can help.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--92961895-38bb-428a-84d3-b90e4b34a1e8-0', usage_metadata={'input_tokens': 10, 'output_tokens': 212, 'total_tokens': 222, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = llm.invoke(message1)\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "49b1b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "message2 = [SystemMessage(content=\"You are a helpful assistant. and you give concise answers.\"),\n",
    "           HumanMessage(content=\"I need your help\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e4dec074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, I'm ready. How can I help you?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--74b56e9d-d65c-43a8-97c4-c23b3819ba40-0', usage_metadata={'input_tokens': 16, 'output_tokens': 14, 'total_tokens': 30, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2 = llm.invoke(message2)\n",
    "response2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e13583",
   "metadata": {},
   "source": [
    "### Using Output Perser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "12bf2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9b5604b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, I'm ready to help! Tell me what you need. The more information you give me, the better I can assist you. For example, you could tell me:\\n\\n*   **What you're trying to achieve:** What is your goal?\\n*   **What you've already tried:** What steps have you taken so far?\\n*   **What problems you're encountering:** What's blocking you?\\n*   **What kind of help you need:** Are you looking for information, code, creative writing, brainstorming, or something else?\\n\\nI can help with a wide range of tasks, including:\\n\\n*   Answering questions\\n*   Generating text (stories, poems, code, etc.)\\n*   Summarizing information\\n*   Translating languages\\n*   Brainstorming ideas\\n*   Providing definitions\\n*   Offering advice (though I'm not a substitute for professional advice)\\n\\nI'm looking forward to hearing from you! Let me know how I can help.\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "parser.invoke(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7031fd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, I'm ready. How can I help you?\""
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbba33c",
   "metadata": {},
   "source": [
    "### Chaining with LCEL\n",
    "- LangChain Expression Language (LCEL) &mdash; a concise syntax for composing and chaining together components (like models and output parsers) in LangChain workflows.LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bd1930dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc29801",
   "metadata": {},
   "source": [
    "- The line `chain = llm | parser` creates a simple pipeline (chain) where the output of the language model (`llm`) is passed directly to the output parser (`parser`). This allows you to process a prompt through the model and automatically parse its response in a single step, making it easier to work with structured outputs in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "872df89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, I'm ready to help! Tell me what you need. The more information you give me, the better I can assist you. For example, you could tell me:\\n\\n*   **What you're trying to achieve:** What is your goal?\\n*   **What you've already tried:** What steps have you taken so far?\\n*   **What problems you're encountering:** What's blocking you?\\n*   **What kind of help you need:** Are you looking for information, code, creative writing, brainstorming, or something else?\\n\\nI can help with a wide range of tasks, including:\\n\\n*   Answering questions\\n*   Generating text (stories, poems, code, etc.)\\n*   Summarizing information\\n*   Translating languages\\n*   Brainstorming ideas\\n*   Providing definitions\\n*   Offering advice (though I'm not a substitute for professional advice)\\n\\nI'm looking forward to hearing from you! Let me know how I can help.\""
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(message1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "96e2c09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, I'm ready. How can I help you?\""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(message2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86599876",
   "metadata": {},
   "source": [
    "### Prompting with PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f333a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2e1b1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You give concise answer and Translate the following text to : {language}\"),\n",
    "     (\"human\", \"{text}\")]\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "410986b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = promt_template.invoke({\"language\": \"Bengali\", \"text\": \"My name is Durjay.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cb7b19e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You give concise answer and Translate the following text to : Bengali', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='My name is Durjay.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5a37e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "55e4d0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আমার নাম Durjay। (Amar naam Durjay.)'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514955f",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f3548f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = promt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3998c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আমার নাম Durjay। (Amar naam Durjay.)'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"Bengali\", \"text\": \"My name is Durjay.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb85ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
