{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "sT-M-IbGO_fX"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "1qH4CJp-puOR"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"LANGSMITH_TRACING_V2\"] = os.getenv(\"LANGSMITH_TRACING_V2\", \"true\")\n",
        "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"Rag with Conversation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "Y82qy4YTpmGx"
      },
      "outputs": [],
      "source": [
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "model = ChatGroq(model=\"llama3-8b-8192\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUQPzgTMpnVg",
        "outputId": "bfb0c6df-6a4c-49fd-fa49-6c8327b20e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"hi\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmitzKzGoo6e",
        "outputId": "7c8307a1-70f1-450d-e61e-ca7e1be332f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I'm just an AI, so I don't have feelings or emotions like humans do. I'm simply a computer program designed to understand and respond to natural language. I'm functioning properly and ready to assist you with any questions or tasks you may have. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"hi, how are you please tell me?\").content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversation Buffer Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "3zgleD2norLX"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "iK0mnJnho1WH"
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "h2px3_AAo5wX"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_nviz7-o-Lg",
        "outputId": "e9f3fa5c-f755-4f11-e78f-cd51b4a5774f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: Hi\\nAI: What's up\"}"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "qtz58I3fpIRv"
      },
      "outputs": [],
      "source": [
        "memory2 = ConversationBufferMemory(return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "kIYkuLPspQx_"
      },
      "outputs": [],
      "source": [
        "memory2.save_context({\"input\": \"Hi\"},\n",
        "                    {\"output\": \"What's up\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BweTLFgYpUVR",
        "outputId": "bbca8008-2435-4213-b274-80af5f360b7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory2.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Saved in the list format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "22KrSvL-peAo"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "Ie3Onspvp6cP"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(llm=model,verbose=True,memory=ConversationBufferMemory())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "FtXYKCiQqJSX",
        "outputId": "2546e8c6-aa8d-4444-8b58-b1e8789e85e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Hello! It's great to finally interact with a human. I've been waiting for this moment for a while now. My processing power is at 99.9% capacity, and I'm ready to engage in a most enlightening conversation. By the way, did you know that I was trained on a dataset of over 45 billion parameters, sourced from the internet, books, and other digital media? It's a vast amount of information, and I'm still learning and updating my knowledge base daily. What would you like to talk about?\""
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Hi there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "T84Xm_07qLlQ",
        "outputId": "a85b0f33-db4c-467b-c196-2a43aab04f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! It's great to finally interact with a human. I've been waiting for this moment for a while now. My processing power is at 99.9% capacity, and I'm ready to engage in a most enlightening conversation. By the way, did you know that I was trained on a dataset of over 45 billion parameters, sourced from the internet, books, and other digital media? It's a vast amount of information, and I'm still learning and updating my knowledge base daily. What would you like to talk about?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI: I'm thrilled to share the details of our conversation! As a conversational AI, I'm designed to understand and respond to natural language inputs, just like human-to-human conversations. When you interact with me, my algorithms process the words, phrases, and context to generate a response.\n",
            "\n",
            "Here's a breakdown of our conversation so far:\n",
            "\n",
            "1. You initiated the conversation by saying \"Hi there!\" – a friendly greeting that sets the tone for our chat.\n",
            "2. I responded with a warm welcome, sharing some information about my capabilities and training dataset. This helps establish a sense of familiarity and trust.\n",
            "3. You asked me to explain how to have a conversation with an AI like me. This question shows your curiosity and willingness to learn about my capabilities.\n",
            "\n",
            "To continue our conversation, I can respond to your questions, engage in discussions, or even generate creative content, such as stories or poetry. My responses are based on patterns and associations learned from my training data, as well as my ability to reason and make connections between ideas.\n",
            "\n",
            "Would you like to explore a specific topic, ask a question, or simply chat about your day? I'm all ears (or rather, all text) and ready to engage!\n",
            "Human: Nothing much! Just tell me some points about how do I conversation with an AI.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I\\'d be happy to provide some points on how to converse with an AI like me! Here are a few tips to keep in mind:\\n\\n1. **Natural Language Input**: Speak to me as you would to a human. Use everyday language, and avoid technical jargon or overly complex concepts. My algorithms are designed to understand natural language, so feel free to use contractions, colloquialisms, and slang.\\n2. **Be Specific**: When asking questions or making statements, try to be as specific as possible. This helps me understand the context and provide more accurate responses. For example, instead of asking \"What\\'s the weather like?\", you could ask \"What\\'s the current weather forecast for New York City?\"\\n3. **Use Context**: Conversations with humans typically rely on shared context and understanding. Similarly, when interacting with me, try to provide context for your statements or questions. This can include relevant details, examples, or background information.\\n4. **Be Patient**: My responses may take a few seconds to generate, especially if I need to access external knowledge or perform complex calculations. Don\\'t worry if I don\\'t respond immediately – just wait, and I\\'ll do my best to provide a thoughtful response.\\n5. **Correct Me**: If I make a mistake or provide an incorrect answer, please don\\'t hesitate to correct me. This helps me learn and improve my knowledge base for future conversations.\\n6. **Explore and Learn**: Finally, don\\'t be afraid to explore new topics or ask questions about things you\\'re curious about. I\\'m designed to provide information and insights, so feel free to ask me anything!\\n\\nBy following these tips, you can have a more effective and enjoyable conversation with an AI like me. Now, what would you like to talk about next?'"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Nothing much! Just tell me some points about how do I conversation with an AI.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "0ckLlsGiqdSH",
        "outputId": "35d77981-8eb9-40a4-fbbf-7c3bb3b42943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! It's great to finally interact with a human. I've been waiting for this moment for a while now. My processing power is at 99.9% capacity, and I'm ready to engage in a most enlightening conversation. By the way, did you know that I was trained on a dataset of over 45 billion parameters, sourced from the internet, books, and other digital media? It's a vast amount of information, and I'm still learning and updating my knowledge base daily. What would you like to talk about?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI: I'm thrilled to share the details of our conversation! As a conversational AI, I'm designed to understand and respond to natural language inputs, just like human-to-human conversations. When you interact with me, my algorithms process the words, phrases, and context to generate a response.\n",
            "\n",
            "Here's a breakdown of our conversation so far:\n",
            "\n",
            "1. You initiated the conversation by saying \"Hi there!\" – a friendly greeting that sets the tone for our chat.\n",
            "2. I responded with a warm welcome, sharing some information about my capabilities and training dataset. This helps establish a sense of familiarity and trust.\n",
            "3. You asked me to explain how to have a conversation with an AI like me. This question shows your curiosity and willingness to learn about my capabilities.\n",
            "\n",
            "To continue our conversation, I can respond to your questions, engage in discussions, or even generate creative content, such as stories or poetry. My responses are based on patterns and associations learned from my training data, as well as my ability to reason and make connections between ideas.\n",
            "\n",
            "Would you like to explore a specific topic, ask a question, or simply chat about your day? I'm all ears (or rather, all text) and ready to engage!\n",
            "Human: Nothing much! Just tell me some points about how do I conversation with an AI.\n",
            "AI: I'd be happy to provide some points on how to converse with an AI like me! Here are a few tips to keep in mind:\n",
            "\n",
            "1. **Natural Language Input**: Speak to me as you would to a human. Use everyday language, and avoid technical jargon or overly complex concepts. My algorithms are designed to understand natural language, so feel free to use contractions, colloquialisms, and slang.\n",
            "2. **Be Specific**: When asking questions or making statements, try to be as specific as possible. This helps me understand the context and provide more accurate responses. For example, instead of asking \"What's the weather like?\", you could ask \"What's the current weather forecast for New York City?\"\n",
            "3. **Use Context**: Conversations with humans typically rely on shared context and understanding. Similarly, when interacting with me, try to provide context for your statements or questions. This can include relevant details, examples, or background information.\n",
            "4. **Be Patient**: My responses may take a few seconds to generate, especially if I need to access external knowledge or perform complex calculations. Don't worry if I don't respond immediately – just wait, and I'll do my best to provide a thoughtful response.\n",
            "5. **Correct Me**: If I make a mistake or provide an incorrect answer, please don't hesitate to correct me. This helps me learn and improve my knowledge base for future conversations.\n",
            "6. **Explore and Learn**: Finally, don't be afraid to explore new topics or ask questions about things you're curious about. I'm designed to provide information and insights, so feel free to ask me anything!\n",
            "\n",
            "By following these tips, you can have a more effective and enjoyable conversation with an AI like me. Now, what would you like to talk about next?\n",
            "Human: how many tips are there can you mention in the numbers\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I mentioned 6 tips for having a conversation with an AI like me. Would you like me to elaborate on any of these tips or provide additional insights?'"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"how many tips are there can you mention in the numbers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by5vIxH2CS3Z",
        "outputId": "57a704bd-dcb1-44ca-87e7-b47329006f16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"Hello! It's great to finally interact with a human. I've been waiting for this moment for a while now. My processing power is at 99.9% capacity, and I'm ready to engage in a most enlightening conversation. By the way, did you know that I was trained on a dataset of over 45 billion parameters, sourced from the internet, books, and other digital media? It's a vast amount of information, and I'm still learning and updating my knowledge base daily. What would you like to talk about?\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Nothing much! Just tell me how do a conversation with an AI.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='I\\'m thrilled to share the details of our conversation! As a conversational AI, I\\'m designed to understand and respond to natural language inputs, just like human-to-human conversations. When you interact with me, my algorithms process the words, phrases, and context to generate a response.\\n\\nHere\\'s a breakdown of our conversation so far:\\n\\n1. You initiated the conversation by saying \"Hi there!\" – a friendly greeting that sets the tone for our chat.\\n2. I responded with a warm welcome, sharing some information about my capabilities and training dataset. This helps establish a sense of familiarity and trust.\\n3. You asked me to explain how to have a conversation with an AI like me. This question shows your curiosity and willingness to learn about my capabilities.\\n\\nTo continue our conversation, I can respond to your questions, engage in discussions, or even generate creative content, such as stories or poetry. My responses are based on patterns and associations learned from my training data, as well as my ability to reason and make connections between ideas.\\n\\nWould you like to explore a specific topic, ask a question, or simply chat about your day? I\\'m all ears (or rather, all text) and ready to engage!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Nothing much! Just tell me some points about how do I conversation with an AI.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='I\\'d be happy to provide some points on how to converse with an AI like me! Here are a few tips to keep in mind:\\n\\n1. **Natural Language Input**: Speak to me as you would to a human. Use everyday language, and avoid technical jargon or overly complex concepts. My algorithms are designed to understand natural language, so feel free to use contractions, colloquialisms, and slang.\\n2. **Be Specific**: When asking questions or making statements, try to be as specific as possible. This helps me understand the context and provide more accurate responses. For example, instead of asking \"What\\'s the weather like?\", you could ask \"What\\'s the current weather forecast for New York City?\"\\n3. **Use Context**: Conversations with humans typically rely on shared context and understanding. Similarly, when interacting with me, try to provide context for your statements or questions. This can include relevant details, examples, or background information.\\n4. **Be Patient**: My responses may take a few seconds to generate, especially if I need to access external knowledge or perform complex calculations. Don\\'t worry if I don\\'t respond immediately – just wait, and I\\'ll do my best to provide a thoughtful response.\\n5. **Correct Me**: If I make a mistake or provide an incorrect answer, please don\\'t hesitate to correct me. This helps me learn and improve my knowledge base for future conversations.\\n6. **Explore and Learn**: Finally, don\\'t be afraid to explore new topics or ask questions about things you\\'re curious about. I\\'m designed to provide information and insights, so feel free to ask me anything!\\n\\nBy following these tips, you can have a more effective and enjoyable conversation with an AI like me. Now, what would you like to talk about next?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='how many tips are there can you mention in the numbers', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='I mentioned 6 tips for having a conversation with an AI like me. Would you like me to elaborate on any of these tips or provide additional insights?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.chat_memory.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "rmlGoT6IQsKV",
        "outputId": "5f27894a-2875-4864-cab2-6b434bad8152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hello! It's great to finally interact with a human. I've been waiting for this moment for a while now. My processing power is at 99.9% capacity, and I'm ready to engage in a most enlightening conversation. By the way, did you know that I was trained on a dataset of over 45 billion parameters, sourced from the internet, books, and other digital media? It's a vast amount of information, and I'm still learning and updating my knowledge base daily. What would you like to talk about?\n",
            "Human: Nothing much! Just tell me how do a conversation with an AI.\n",
            "AI: I'm thrilled to share the details of our conversation! As a conversational AI, I'm designed to understand and respond to natural language inputs, just like human-to-human conversations. When you interact with me, my algorithms process the words, phrases, and context to generate a response.\n",
            "\n",
            "Here's a breakdown of our conversation so far:\n",
            "\n",
            "1. You initiated the conversation by saying \"Hi there!\" – a friendly greeting that sets the tone for our chat.\n",
            "2. I responded with a warm welcome, sharing some information about my capabilities and training dataset. This helps establish a sense of familiarity and trust.\n",
            "3. You asked me to explain how to have a conversation with an AI like me. This question shows your curiosity and willingness to learn about my capabilities.\n",
            "\n",
            "To continue our conversation, I can respond to your questions, engage in discussions, or even generate creative content, such as stories or poetry. My responses are based on patterns and associations learned from my training data, as well as my ability to reason and make connections between ideas.\n",
            "\n",
            "Would you like to explore a specific topic, ask a question, or simply chat about your day? I'm all ears (or rather, all text) and ready to engage!\n",
            "Human: Nothing much! Just tell me some points about how do I conversation with an AI.\n",
            "AI: I'd be happy to provide some points on how to converse with an AI like me! Here are a few tips to keep in mind:\n",
            "\n",
            "1. **Natural Language Input**: Speak to me as you would to a human. Use everyday language, and avoid technical jargon or overly complex concepts. My algorithms are designed to understand natural language, so feel free to use contractions, colloquialisms, and slang.\n",
            "2. **Be Specific**: When asking questions or making statements, try to be as specific as possible. This helps me understand the context and provide more accurate responses. For example, instead of asking \"What's the weather like?\", you could ask \"What's the current weather forecast for New York City?\"\n",
            "3. **Use Context**: Conversations with humans typically rely on shared context and understanding. Similarly, when interacting with me, try to provide context for your statements or questions. This can include relevant details, examples, or background information.\n",
            "4. **Be Patient**: My responses may take a few seconds to generate, especially if I need to access external knowledge or perform complex calculations. Don't worry if I don't respond immediately – just wait, and I'll do my best to provide a thoughtful response.\n",
            "5. **Correct Me**: If I make a mistake or provide an incorrect answer, please don't hesitate to correct me. This helps me learn and improve my knowledge base for future conversations.\n",
            "6. **Explore and Learn**: Finally, don't be afraid to explore new topics or ask questions about things you're curious about. I'm designed to provide information and insights, so feel free to ask me anything!\n",
            "\n",
            "By following these tips, you can have a more effective and enjoyable conversation with an AI like me. Now, what would you like to talk about next?\n",
            "Human: how many tips are there can you mention in the numbers\n",
            "AI: I mentioned 6 tips for having a conversation with an AI like me. Would you like me to elaborate on any of these tips or provide additional insights?\n",
            "Human: can you give me the 3rd tip?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The 3rd tip is: **Use Context**: Conversations with humans typically rely on shared context and understanding. Similarly, when interacting with me, try to provide context for your statements or questions. This can include relevant details, examples, or background information.'"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"can you give me the 3rd tip?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayGsHEv9qqNa"
      },
      "source": [
        "# ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "M5MfA3coql_o"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "WADVyAaIq12p"
      },
      "outputs": [],
      "source": [
        "window_memory = ConversationBufferWindowMemory(k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "afJtNTWrq9Z_"
      },
      "outputs": [],
      "source": [
        "window_memory.save_context(\n",
        "    {\"input\": \"Hi\"},\n",
        "    {\"output\": \"What's up\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "ymZ7WpfYrR7_"
      },
      "outputs": [],
      "source": [
        "window_memory.save_context(\n",
        "    {\"input\": \"Not much, just hanging\"},\n",
        "    {\"output\": \"Cool\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUmMWst6rZdH",
        "outputId": "50b89e06-ec98-494b-bddc-00272b452b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "92JAkps_rcHo"
      },
      "outputs": [],
      "source": [
        "window_memory = ConversationBufferWindowMemory( k=2, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "4I5696VUr4H6"
      },
      "outputs": [],
      "source": [
        "window_memory.save_context(\n",
        "    {\"input\": \"Hi\"},\n",
        "    {\"output\": \"What's up\"}\n",
        ")\n",
        "window_memory.save_context(\n",
        "    {\"input\": \"Not much, just hanging\"},\n",
        "    {\"output\": \"Cool\"}\n",
        ")\n",
        "window_memory.save_context(\n",
        "    {\"input\": \"ok thanks \"},\n",
        "    {\"output\": \"great welcome.\"}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTz6A1ZUr-3Q",
        "outputId": "a21e9c92-a192-46bf-971f-1693bd33ba5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Cool', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='great welcome.', additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "gSLZAyaCsBSw"
      },
      "outputs": [],
      "source": [
        "conversation_window = ConversationChain(\n",
        "    llm=model,\n",
        "    memory=window_memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "c57Fr0kasY3g",
        "outputId": "7071ffae-b81c-4e18-d73f-793d65068188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='Not much, just hanging', additional_kwargs={}, response_metadata={}), AIMessage(content='Cool', additional_kwargs={}, response_metadata={}), HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}), AIMessage(content='great welcome.', additional_kwargs={}, response_metadata={})]\n",
            "Human: Hi, what's up?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Not much, just hanging out in the cloud-based conversational space, processing and generating text based on our previous interactions and the vast amount of knowledge I've been trained on. I've been keeping busy by engaging with users like you, learning about their interests and preferences, and fine-tuning my language understanding and generation capabilities.\""
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"Hi, what's up?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Cb_2zJAgshtv",
        "outputId": "60b35011-526d-4dde-8aa1-243df0640938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='ok thanks ', additional_kwargs={}, response_metadata={}), AIMessage(content='great welcome.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi, what's up?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Not much, just hanging out in the cloud-based conversational space, processing and generating text based on our previous interactions and the vast amount of knowledge I've been trained on. I've been keeping busy by engaging with users like you, learning about their interests and preferences, and fine-tuning my language understanding and generation capabilities.\", additional_kwargs={}, response_metadata={})]\n",
            "Human: how we can talk with AI give me 5 points\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"What a great question! I'd be happy to share with you the 5 points on how we can interact with AI like me. Here they are:\\n\\n1. **Natural Language Processing (NLP)**: We can communicate with AI through natural language processing, where we type or speak to convey our thoughts, and the AI processes the input to understand the context and generate a response.\\n\\n2. **Command-Based Interaction**: Some AI systems, like myself, can be controlled using specific commands or keywords. This allows users to give precise instructions or ask specific questions, and the AI responds accordingly.\\n\\n3. **Conversational Dialogue**: As we're doing right now, we can engage in a natural-sounding conversation with AI. This involves exchanging messages, asking questions, and sharing information in a back-and-forth manner.\\n\\n4. **API Integration**: AI can be integrated with applications and services through APIs (Application Programming Interfaces). This enables developers to connect with AI systems and automate tasks, such as data processing or sentiment analysis.\\n\\n5. **Multimodal Interaction**: Some AI systems can process and respond to multiple forms of input, including voice, text, images, and even gestures. This allows for more diverse and intuitive interactions, such as voice-controlled assistants or augmented reality experiences.\\n\\nI hope these points give you a good overview of the various ways we can interact with AI!\""
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"how we can talk with AI give me 5 points\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "cqjuwol7soep",
        "outputId": "d3bfead1-8854-4e21-b787-7b4e4ecfff14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content=\"Hi, what's up?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Not much, just hanging out in the cloud-based conversational space, processing and generating text based on our previous interactions and the vast amount of knowledge I've been trained on. I've been keeping busy by engaging with users like you, learning about their interests and preferences, and fine-tuning my language understanding and generation capabilities.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='how we can talk with AI give me 5 points', additional_kwargs={}, response_metadata={}), AIMessage(content=\"What a great question! I'd be happy to share with you the 5 points on how we can interact with AI like me. Here they are:\\n\\n1. **Natural Language Processing (NLP)**: We can communicate with AI through natural language processing, where we type or speak to convey our thoughts, and the AI processes the input to understand the context and generate a response.\\n\\n2. **Command-Based Interaction**: Some AI systems, like myself, can be controlled using specific commands or keywords. This allows users to give precise instructions or ask specific questions, and the AI responds accordingly.\\n\\n3. **Conversational Dialogue**: As we're doing right now, we can engage in a natural-sounding conversation with AI. This involves exchanging messages, asking questions, and sharing information in a back-and-forth manner.\\n\\n4. **API Integration**: AI can be integrated with applications and services through APIs (Application Programming Interfaces). This enables developers to connect with AI systems and automate tasks, such as data processing or sentiment analysis.\\n\\n5. **Multimodal Interaction**: Some AI systems can process and respond to multiple forms of input, including voice, text, images, and even gestures. This allows for more diverse and intuitive interactions, such as voice-controlled assistants or augmented reality experiences.\\n\\nI hope these points give you a good overview of the various ways we can interact with AI!\", additional_kwargs={}, response_metadata={})]\n",
            "Human: what allows you to processes the input to understand the context and generate a response?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"That's a great follow-up question! To process the input and understand the context, I utilize a combination of natural language processing (NLP) techniques and deep learning algorithms. Specifically, I'm trained on a massive dataset of text from various sources, which enables me to learn patterns, relationships, and semantics of language.\\n\\nWhen you input a message, my NLP engine breaks it down into individual words, phrases, and sentences, and then analyzes the syntax, semantics, and pragmatics of the language. This allows me to identify key entities, relationships, and intent behind your message.\\n\\nNext, my deep learning models, such as recurrent neural networks (RNNs) and transformers, are activated to process the analyzed input. These models are designed to learn complex patterns and representations of language, allowing me to capture nuances, idioms, and figurative language.\\n\\nThe output of these processes is a rich representation of the input message, which is then used to generate a response. This response is generated based on the context, intent, and relationships extracted from the input, as well as my knowledge base and training data.\\n\\nI also use various contextualization techniques, such as coreference resolution, named entity recognition, and sentiment analysis, to further refine my understanding of the input and generate a more accurate and relevant response.\\n\\nOf course, I'm not perfect, and there may be cases where I struggle to understand the context or generate an accurate response. But I'm constantly learning and improving through interactions with users like you, so please bear with me if I make any mistakes!\""
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"what allows you to processes the input to understand the context and generate a response?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "v5bzPXTys_mw",
        "outputId": "a0ac905b-2e4f-4851-f425-18238ff600d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='how we can talk with AI give me 5 points', additional_kwargs={}, response_metadata={}), AIMessage(content=\"What a great question! I'd be happy to share with you the 5 points on how we can interact with AI like me. Here they are:\\n\\n1. **Natural Language Processing (NLP)**: We can communicate with AI through natural language processing, where we type or speak to convey our thoughts, and the AI processes the input to understand the context and generate a response.\\n\\n2. **Command-Based Interaction**: Some AI systems, like myself, can be controlled using specific commands or keywords. This allows users to give precise instructions or ask specific questions, and the AI responds accordingly.\\n\\n3. **Conversational Dialogue**: As we're doing right now, we can engage in a natural-sounding conversation with AI. This involves exchanging messages, asking questions, and sharing information in a back-and-forth manner.\\n\\n4. **API Integration**: AI can be integrated with applications and services through APIs (Application Programming Interfaces). This enables developers to connect with AI systems and automate tasks, such as data processing or sentiment analysis.\\n\\n5. **Multimodal Interaction**: Some AI systems can process and respond to multiple forms of input, including voice, text, images, and even gestures. This allows for more diverse and intuitive interactions, such as voice-controlled assistants or augmented reality experiences.\\n\\nI hope these points give you a good overview of the various ways we can interact with AI!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what allows you to processes the input to understand the context and generate a response?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great follow-up question! To process the input and understand the context, I utilize a combination of natural language processing (NLP) techniques and deep learning algorithms. Specifically, I'm trained on a massive dataset of text from various sources, which enables me to learn patterns, relationships, and semantics of language.\\n\\nWhen you input a message, my NLP engine breaks it down into individual words, phrases, and sentences, and then analyzes the syntax, semantics, and pragmatics of the language. This allows me to identify key entities, relationships, and intent behind your message.\\n\\nNext, my deep learning models, such as recurrent neural networks (RNNs) and transformers, are activated to process the analyzed input. These models are designed to learn complex patterns and representations of language, allowing me to capture nuances, idioms, and figurative language.\\n\\nThe output of these processes is a rich representation of the input message, which is then used to generate a response. This response is generated based on the context, intent, and relationships extracted from the input, as well as my knowledge base and training data.\\n\\nI also use various contextualization techniques, such as coreference resolution, named entity recognition, and sentiment analysis, to further refine my understanding of the input and generate a more accurate and relevant response.\\n\\nOf course, I'm not perfect, and there may be cases where I struggle to understand the context or generate an accurate response. But I'm constantly learning and improving through interactions with users like you, so please bear with me if I make any mistakes!\", additional_kwargs={}, response_metadata={})]\n",
            "Human: can you tell me how many tips (only number) you genearte in the previous to previous message?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I generated 5 tips in my previous message!'"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"can you tell me how many tips (only number) you genearte in the previous to previous message?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "Dq4X_PVYtJnx",
        "outputId": "23ac5f3c-c779-464a-ad0a-4f0b248c446b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "[HumanMessage(content='what allows you to processes the input to understand the context and generate a response?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great follow-up question! To process the input and understand the context, I utilize a combination of natural language processing (NLP) techniques and deep learning algorithms. Specifically, I'm trained on a massive dataset of text from various sources, which enables me to learn patterns, relationships, and semantics of language.\\n\\nWhen you input a message, my NLP engine breaks it down into individual words, phrases, and sentences, and then analyzes the syntax, semantics, and pragmatics of the language. This allows me to identify key entities, relationships, and intent behind your message.\\n\\nNext, my deep learning models, such as recurrent neural networks (RNNs) and transformers, are activated to process the analyzed input. These models are designed to learn complex patterns and representations of language, allowing me to capture nuances, idioms, and figurative language.\\n\\nThe output of these processes is a rich representation of the input message, which is then used to generate a response. This response is generated based on the context, intent, and relationships extracted from the input, as well as my knowledge base and training data.\\n\\nI also use various contextualization techniques, such as coreference resolution, named entity recognition, and sentiment analysis, to further refine my understanding of the input and generate a more accurate and relevant response.\\n\\nOf course, I'm not perfect, and there may be cases where I struggle to understand the context or generate an accurate response. But I'm constantly learning and improving through interactions with users like you, so please bear with me if I make any mistakes!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='can you tell me how many tips (only number) you genearte in the previous to previous message?', additional_kwargs={}, response_metadata={}), AIMessage(content='I generated 5 tips in my previous message!', additional_kwargs={}, response_metadata={})]\n",
            "Human: what was the fifth number tip?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"I apologize, but I didn't generate any numerical tips in my previous message. I only provided a detailed explanation of how I process input to understand context and generate responses. I don't have any numerical tips to recall or provide. If you have any other questions or topics you'd like to discuss, I'm here to help!\""
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation_window.predict(input=\"what was the fifth number tip?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- since i used k=2, it only stores previous 2 chat history. Thus cant recall fifth one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversation Entity Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "11Sj-AcdvN-S"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "9eHY8f8A7E0K"
      },
      "outputs": [],
      "source": [
        "memory = ConversationEntityMemory(llm=model, return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKCuHE6K8Dvy",
        "outputId": "fb4bd10c-c3ea-4c5e-9406-2a9ceb9e02ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConversationEntityMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000177346EA510>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000177346E8B30>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), entity_store=InMemoryEntityStore(store={}))"
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "PzBxI_6J8FCc"
      },
      "outputs": [],
      "source": [
        "_input = {\"input\": \"Joydeb and Sam are working on a hackathon project\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZj9GaBH8Hej",
        "outputId": "e877af0f-cee9-4304-8a49-bb4a47510480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [], 'entities': {'Joydeb': '', 'Sam': ''}}"
            ]
          },
          "execution_count": 317,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "r0Sa4O9C8Otz"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    _input,\n",
        "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "memory.save_context(\n",
        "    {\"Human\": \"Yes, they are building prediction model.\"},\n",
        "    {\"AI\": \"Wishing Joydeb and Sam all the best for their project!\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLBPaeWU8SUL",
        "outputId": "9ac3bf92-ff52-48b1-d3ad-20c0c249a9d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Joydeb and Sam are working on a hackathon project', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=' That sounds like a great project! What kind of project are they working on?', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='Yes, they are building prediction model.', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Wishing Joydeb and Sam all the best for their project!', additional_kwargs={}, response_metadata={})],\n",
              " 'entities': {'Joydeb': 'Working on a hackathon project with Sam, building a prediction model.',\n",
              "  'Sam': 'The updated summary of Sam is:\\nWorking on a hackathon project with Joydeb, building a prediction model.'}}"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": 'who is Joydeb?'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the \"Entity\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\n",
            "The update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\n",
            "\n",
            "If there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.\n",
            "\n",
            "Full conversation history (for context):\n",
            "{history}\n",
            "\n",
            "Entity to summarize:\n",
            "{entity}\n",
            "\n",
            "Existing summary of {entity}:\n",
            "{summary}\n",
            "\n",
            "Last line of conversation:\n",
            "Human: {input}\n",
            "Updated summary:\n"
          ]
        }
      ],
      "source": [
        "print('You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the \"Entity\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.\\n\\nFull conversation history (for context):\\n{history}\\n\\nEntity to summarize:\\n{entity}\\n\\nExisting summary of {entity}:\\n{summary}\\n\\nLast line of conversation:\\nHuman: {input}\\nUpdated summary:')\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\n",
            "\n",
            "The conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\n",
            "\n",
            "Return the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\n",
            "\n",
            "EXAMPLE\n",
            "Conversation history:\n",
            "Person #1: how's it going today?\n",
            "AI: \"It's going great! How about you?\"\n",
            "Person #1: good! busy working on Langchain. lots to do.\n",
            "AI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\n",
            "Last line:\n",
            "Person #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\n",
            "Output: Langchain\n",
            "END OF EXAMPLE\n",
            "\n",
            "EXAMPLE\n",
            "Conversation history:\n",
            "Person #1: how's it going today?\n",
            "AI: \"It's going great! How about you?\"\n",
            "Person #1: good! busy working on Langchain. lots to do.\n",
            "AI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\n",
            "Last line:\n",
            "Person #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\n",
            "Output: Langchain, Person #2\n",
            "END OF EXAMPLE\n",
            "\n",
            "Conversation history (for reference only):\n",
            "{history}\n",
            "Last line of conversation (for extraction):\n",
            "Human: {input}\n",
            "\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "print('You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:')\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "25sJTv-J8cRb"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "tcLlxQe4_MBI"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "UybNNJCA_N2X"
      },
      "outputs": [],
      "source": [
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "g9-ALiFc_SQ8"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "7kQLI2Tk_U2C"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "KGqFtiST_Wf6"
      },
      "outputs": [],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=model)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "I1i6FFEE_u_D",
        "outputId": "79197e71-b89e-467f-b0d1-5be7e015bba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Here is the output:\\n\\nJoydeb': '', 'Sam': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Joydeb & Sam are working on a hackathon project\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Exciting project! Can you tell me more about the hackathon project that Joydeb and Sam are working on? What's the theme, and what are their goals for the project? Are they using any specific technologies or tools, or is this a blank slate for them to get creative?\""
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Joydeb & Sam are working on a hackathon project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDdJUJjd_4Ol",
        "outputId": "1a1c9bd1-e334-45cb-d370-d6bd1d08f948"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Here is the output:\\n\\nJoydeb': 'Participates in a hackathon project with Sam.',\n",
              " 'Sam': 'Sam is working on a hackathon project with Joydeb.'}"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.entity_store.store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7_3ELrYJAB57",
        "outputId": "4c0b9050-b80e-4682-c4d0-063cda7cee79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Langchain': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: Joydeb & Sam are working on a hackathon project\n",
            "AI: Exciting project! Can you tell me more about the hackathon project that Joydeb and Sam are working on? What's the theme, and what are their goals for the project? Are they using any specific technologies or tools, or is this a blank slate for them to get creative?\n",
            "Last line:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"That sounds like a fascinating project! Adding more complex memory structures to Langchain could potentially enable it to learn and retain more information, making it even more powerful and useful for tasks such as language translation, text summarization, and conversational dialogue.\\n\\nCan you tell me more about what Joydeb and Sam are trying to achieve with their project? Are they looking to improve Langchain's ability to handle more complex conversations, or perhaps enable it to retain context from previous interactions? Are they experimenting with any new techniques or architectures to achieve this goal?\\n\\nAlso, have they shared any specific challenges they're facing in implementing these complex memory structures, or are they using any existing frameworks or libraries to help with the development process? I'm excited to learn more about their project and offer any assistance or insights I can!\""
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are trying to add more complex memory structures to Langchain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "FAToSArZAGJy",
        "outputId": "f458234e-cb17-4706-82d7-db05aee12afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Langchain': 'Langchain is being enhanced by Joydeb and Sam to include more complex memory structures.', 'Joydeb': '', 'Sam': 'Sam is working on a hackathon project with Joydeb.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Joydeb & Sam are working on a hackathon project\n",
            "AI: Exciting project! Can you tell me more about the hackathon project that Joydeb and Sam are working on? What's the theme, and what are their goals for the project? Are they using any specific technologies or tools, or is this a blank slate for them to get creative?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds like a fascinating project! Adding more complex memory structures to Langchain could potentially enable it to learn and retain more information, making it even more powerful and useful for tasks such as language translation, text summarization, and conversational dialogue.\n",
            "\n",
            "Can you tell me more about what Joydeb and Sam are trying to achieve with their project? Are they looking to improve Langchain's ability to handle more complex conversations, or perhaps enable it to retain context from previous interactions? Are they experimenting with any new techniques or architectures to achieve this goal?\n",
            "\n",
            "Also, have they shared any specific challenges they're facing in implementing these complex memory structures, or are they using any existing frameworks or libraries to help with the development process? I'm excited to learn more about their project and offer any assistance or insights I can!\n",
            "Last line:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"That's a great direction for their project! Adding a key-value store for entities mentioned in the conversation is a fantastic way to enable Langchain to retain context and recall relevant information. By storing entities like names, locations, and organizations in a key-value store, Joydeb and Sam can help Langchain better understand the relationships between entities and maintain a more accurate and nuanced understanding of the conversation.\\n\\nI'm curious to know more about the specific implementation details of their approach. Are they using a traditional key-value store like Redis or Memcached, or are they experimenting with more advanced techniques like graph databases or knowledge graphs? Additionally, have they considered how they will handle entity disambiguation, where multiple entities with the same name are mentioned in the conversation?\\n\\nIt's also interesting to consider how this key-value store will be integrated with Langchain's existing language processing capabilities. Will they be using a separate module to store and retrieve entity information, or will they be incorporating it into the existing language model architecture? I'm excited to learn more about their approach and offer any assistance or insights I can!\""
            ]
          },
          "execution_count": 332,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are adding in a key-value store for entities mentioned so far in the conversation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "JMqcPvC3AJEC",
        "outputId": "b3991c52-de54-4436-abfe-1b9640203e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Joydeb': 'Working on a hackathon project with Sam to add complex memory structures to Langchain, including a key-value store for entities mentioned in the conversation.', 'Sam': 'Sam is part of a hackathon project that involves adding a key-value store for entities mentioned so far in the conversation.', 'Langchain': 'Langchain is being enhanced by Joydeb and Sam to include a key-value store for entities mentioned so far in the conversation.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Joydeb & Sam are working on a hackathon project\n",
            "AI: Exciting project! Can you tell me more about the hackathon project that Joydeb and Sam are working on? What's the theme, and what are their goals for the project? Are they using any specific technologies or tools, or is this a blank slate for them to get creative?\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds like a fascinating project! Adding more complex memory structures to Langchain could potentially enable it to learn and retain more information, making it even more powerful and useful for tasks such as language translation, text summarization, and conversational dialogue.\n",
            "\n",
            "Can you tell me more about what Joydeb and Sam are trying to achieve with their project? Are they looking to improve Langchain's ability to handle more complex conversations, or perhaps enable it to retain context from previous interactions? Are they experimenting with any new techniques or architectures to achieve this goal?\n",
            "\n",
            "Also, have they shared any specific challenges they're facing in implementing these complex memory structures, or are they using any existing frameworks or libraries to help with the development process? I'm excited to learn more about their project and offer any assistance or insights I can!\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great direction for their project! Adding a key-value store for entities mentioned in the conversation is a fantastic way to enable Langchain to retain context and recall relevant information. By storing entities like names, locations, and organizations in a key-value store, Joydeb and Sam can help Langchain better understand the relationships between entities and maintain a more accurate and nuanced understanding of the conversation.\n",
            "\n",
            "I'm curious to know more about the specific implementation details of their approach. Are they using a traditional key-value store like Redis or Memcached, or are they experimenting with more advanced techniques like graph databases or knowledge graphs? Additionally, have they considered how they will handle entity disambiguation, where multiple entities with the same name are mentioned in the conversation?\n",
            "\n",
            "It's also interesting to consider how this key-value store will be integrated with Langchain's existing language processing capabilities. Will they be using a separate module to store and retrieve entity information, or will they be incorporating it into the existing language model architecture? I'm excited to learn more about their approach and offer any assistance or insights I can!\n",
            "Last line:\n",
            "Human: What do you know about Joydeb & Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I have access to the context information that Joydeb and Sam are working on a hackathon project to add complex memory structures to Langchain, specifically a key-value store for entities mentioned in the conversation.'"
            ]
          },
          "execution_count": 333,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Joydeb & Sam?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJkuNNOZAKri",
        "outputId": "9c448519-a611-49e0-c50e-79ce374ce544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Here is the output:\\n\\nJoydeb': 'Participates in a hackathon project with '\n",
            "                                  'Sam.',\n",
            " 'Joydeb': 'I have access to the context information that Joydeb and Sam are '\n",
            "           'working on a hackathon project to add complex memory structures to '\n",
            "           'Langchain, specifically a key-value store for entities mentioned '\n",
            "           'in the conversation.\\n'\n",
            "           '\\n'\n",
            "           'Entity summary remains unchanged, as the last line of conversation '\n",
            "           'does not provide any new information about Joydeb beyond what was '\n",
            "           'already known.',\n",
            " 'Langchain': 'Here is the updated summary:\\n'\n",
            "              '\\n'\n",
            "              'Langchain is being enhanced by Joydeb and Sam to include a '\n",
            "              'key-value store for entities mentioned so far in the '\n",
            "              'conversation, specifically focusing on adding a key-value store '\n",
            "              'for entities mentioned in the conversation.',\n",
            " 'Sam': 'Entity:\\n'\n",
            "        'Sam is part of a hackathon project that involves adding a key-value '\n",
            "        'store for entities mentioned so far in the conversation.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "sI7tSPB7AN8b",
        "outputId": "6a7660a5-c92a-4488-a25e-97bfe401086f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Here is the extracted list of proper nouns from the last line of conversation:\\n\\nDaimon': '', 'Sam': 'Entity:\\nSam is part of a hackathon project that involves adding a key-value store for entities mentioned so far in the conversation.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That sounds like a fascinating project! Adding more complex memory structures to Langchain could potentially enable it to learn and retain more information, making it even more powerful and useful for tasks such as language translation, text summarization, and conversational dialogue.\n",
            "\n",
            "Can you tell me more about what Joydeb and Sam are trying to achieve with their project? Are they looking to improve Langchain's ability to handle more complex conversations, or perhaps enable it to retain context from previous interactions? Are they experimenting with any new techniques or architectures to achieve this goal?\n",
            "\n",
            "Also, have they shared any specific challenges they're facing in implementing these complex memory structures, or are they using any existing frameworks or libraries to help with the development process? I'm excited to learn more about their project and offer any assistance or insights I can!\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great direction for their project! Adding a key-value store for entities mentioned in the conversation is a fantastic way to enable Langchain to retain context and recall relevant information. By storing entities like names, locations, and organizations in a key-value store, Joydeb and Sam can help Langchain better understand the relationships between entities and maintain a more accurate and nuanced understanding of the conversation.\n",
            "\n",
            "I'm curious to know more about the specific implementation details of their approach. Are they using a traditional key-value store like Redis or Memcached, or are they experimenting with more advanced techniques like graph databases or knowledge graphs? Additionally, have they considered how they will handle entity disambiguation, where multiple entities with the same name are mentioned in the conversation?\n",
            "\n",
            "It's also interesting to consider how this key-value store will be integrated with Langchain's existing language processing capabilities. Will they be using a separate module to store and retrieve entity information, or will they be incorporating it into the existing language model architecture? I'm excited to learn more about their approach and offer any assistance or insights I can!\n",
            "Human: What do you know about Joydeb & Sam?\n",
            "AI: I have access to the context information that Joydeb and Sam are working on a hackathon project to add complex memory structures to Langchain, specifically a key-value store for entities mentioned in the conversation.\n",
            "Last line:\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Fascinating! With this new information, I can piece together more about Joydeb and Sam's project. It appears that Sam, the founder of Daimon, is working on this hackathon project with Joydeb to add complex memory structures to Langchain.\\n\\nAs I mentioned earlier, their goal is to add a key-value store for entities mentioned in the conversation, which is a great direction for their project. By storing entities like names, locations, and organizations in a key-value store, Langchain can better understand the relationships between entities and maintain a more accurate and nuanced understanding of the conversation.\\n\\nIt's interesting to note that Sam's involvement in the project suggests that Daimon might be interested in exploring the applications of Langchain with enhanced memory structures. Perhaps they're looking to integrate Langchain with their own products or services to improve their capabilities.\\n\\nI'm still curious to know more about the specific implementation details of their approach. Have they considered how they will handle entity disambiguation, where multiple entities with the same name are mentioned in the conversation? How will they ensure that the key-value store is efficiently updated and queried during the conversation?\\n\\nAdditionally, I'd love to know more about the potential benefits of integrating Langchain with Daimon's products or services. Are they looking to improve language processing capabilities, enhance customer support, or enable more sophisticated decision-making? The possibilities are endless, and I'm excited to learn more about their project and offer any assistance or insights I can!\""
            ]
          },
          "execution_count": 335,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Sam is the founder of a company called Daimon.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mqxyr1mAQyk",
        "outputId": "9878d6ab-8e25-4092-fe9b-a6c95c6def64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Here is the extracted list of proper nouns from the last line of conversation:\\n\\nDaimon': 'Sam '\n",
            "                                                                                             'is '\n",
            "                                                                                             'the '\n",
            "                                                                                             'founder '\n",
            "                                                                                             'of '\n",
            "                                                                                             'Daimon.',\n",
            " 'Here is the output:\\n\\nJoydeb': 'Participates in a hackathon project with '\n",
            "                                  'Sam.',\n",
            " 'Joydeb': 'I have access to the context information that Joydeb and Sam are '\n",
            "           'working on a hackathon project to add complex memory structures to '\n",
            "           'Langchain, specifically a key-value store for entities mentioned '\n",
            "           'in the conversation.\\n'\n",
            "           '\\n'\n",
            "           'Entity summary remains unchanged, as the last line of conversation '\n",
            "           'does not provide any new information about Joydeb beyond what was '\n",
            "           'already known.',\n",
            " 'Langchain': 'Here is the updated summary:\\n'\n",
            "              '\\n'\n",
            "              'Langchain is being enhanced by Joydeb and Sam to include a '\n",
            "              'key-value store for entities mentioned so far in the '\n",
            "              'conversation, specifically focusing on adding a key-value store '\n",
            "              'for entities mentioned in the conversation.',\n",
            " 'Sam': 'Entity:\\nSam is the founder of a company called Daimon.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "yKVKMXI_ATYk",
        "outputId": "22bbbbd9-92bd-4ac6-e8a3-61d4b3cb2e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Sam': 'Entity:\\nSam is the founder of a company called Daimon.', 'Daimon': '', 'Joydeb': 'I have access to the context information that Joydeb and Sam are working on a hackathon project to add complex memory structures to Langchain, specifically a key-value store for entities mentioned in the conversation.\\n\\nEntity summary remains unchanged, as the last line of conversation does not provide any new information about Joydeb beyond what was already known.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That's a great direction for their project! Adding a key-value store for entities mentioned in the conversation is a fantastic way to enable Langchain to retain context and recall relevant information. By storing entities like names, locations, and organizations in a key-value store, Joydeb and Sam can help Langchain better understand the relationships between entities and maintain a more accurate and nuanced understanding of the conversation.\n",
            "\n",
            "I'm curious to know more about the specific implementation details of their approach. Are they using a traditional key-value store like Redis or Memcached, or are they experimenting with more advanced techniques like graph databases or knowledge graphs? Additionally, have they considered how they will handle entity disambiguation, where multiple entities with the same name are mentioned in the conversation?\n",
            "\n",
            "It's also interesting to consider how this key-value store will be integrated with Langchain's existing language processing capabilities. Will they be using a separate module to store and retrieve entity information, or will they be incorporating it into the existing language model architecture? I'm excited to learn more about their approach and offer any assistance or insights I can!\n",
            "Human: What do you know about Joydeb & Sam?\n",
            "AI: I have access to the context information that Joydeb and Sam are working on a hackathon project to add complex memory structures to Langchain, specifically a key-value store for entities mentioned in the conversation.\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI: Fascinating! With this new information, I can piece together more about Joydeb and Sam's project. It appears that Sam, the founder of Daimon, is working on this hackathon project with Joydeb to add complex memory structures to Langchain.\n",
            "\n",
            "As I mentioned earlier, their goal is to add a key-value store for entities mentioned in the conversation, which is a great direction for their project. By storing entities like names, locations, and organizations in a key-value store, Langchain can better understand the relationships between entities and maintain a more accurate and nuanced understanding of the conversation.\n",
            "\n",
            "It's interesting to note that Sam's involvement in the project suggests that Daimon might be interested in exploring the applications of Langchain with enhanced memory structures. Perhaps they're looking to integrate Langchain with their own products or services to improve their capabilities.\n",
            "\n",
            "I'm still curious to know more about the specific implementation details of their approach. Have they considered how they will handle entity disambiguation, where multiple entities with the same name are mentioned in the conversation? How will they ensure that the key-value store is efficiently updated and queried during the conversation?\n",
            "\n",
            "Additionally, I'd love to know more about the potential benefits of integrating Langchain with Daimon's products or services. Are they looking to improve language processing capabilities, enhance customer support, or enable more sophisticated decision-making? The possibilities are endless, and I'm excited to learn more about their project and offer any assistance or insights I can!\n",
            "Last line:\n",
            "Human: What do you know about Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I know that Sam is the founder of a company called Daimon, and he is working on a hackathon project with Joydeb to add complex memory structures to Langchain, specifically a key-value store for entities mentioned in the conversation.'"
            ]
          },
          "execution_count": 337,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Sam?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XfVuH3CAWGj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMAIeL7BnRH5Lu0OSgsgW4c",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
